created_by: IBM
seed_examples:
- answer: 'This paper introduces a post-processing technique to improve the utility
    of the synthetic data with respect to measures selected by the end user, while
    preserving strong privacy guarantees and dataset quality. This advancement improves
    the utility of data for downstream use.

    '
  document: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'What is the main contribution of this paper in 2 sentences?

    '
- answer: 'The authors resampled from the synthetic data to filter out samples that
    do not meet the selected utility measures. They used an efficient stochastic first-order
    algorithm to find optimal resampling weights.

    '
  document: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: What makes it better than other techniques?
- answer: 'Through comprehensive numerical experiments, the authors demonstrated that
    the approach they outlined improves the utility of synthetic data across multiple
    benchmark datasets and state-of-the-art synthetic data generation algorithms.

    '
  document: "## Post-processing Private Synthetic Data for Improving Utility on Selected\
    \ Measures\n\nHao Wang, Shivchander Sudalairaj, John Henning, Kristjan Greenewald,\
    \ Akash Srivastava \u2217 MIT-IBM Watson AI Lab\n\n## Abstract\n\nExisting private\
    \ synthetic data generation algorithms are agnostic to downstream tasks. However,\
    \ end users may have specific requirements that the synthetic data must satisfy.\
    \ Failure to meet these requirements could significantly reduce the utility of\
    \ the data for downstream use. We introduce a post-processing technique that improves\
    \ the utility of the synthetic data with respect to measures selected by the end\
    \ user, while preserving strong privacy guarantees and dataset quality. Our technique\
    \ involves resampling from the synthetic data to filter out samples that do not\
    \ meet the selected utility measures, using an efficient stochastic first-order\
    \ algorithm to find optimal resampling weights. Through comprehensive numerical\
    \ experiments, we demonstrate that our approach consistently improves the utility\
    \ of synthetic data across multiple benchmark datasets and state-of-the-art synthetic\
    \ data generation algorithms.\n\n## 1 Introduction\n\nThe advancement of machine\
    \ learning (ML) techniques relies on large amounts of training data. However,\
    \ data collection also poses a significant risk of exposing private information.\
    \ In recent years, several instances of privacy breaches have surfaced [NS06,\
    \ Con18], making it urgent to find a reliable way to share data. Today, the de\
    \ facto standard for privacy protection is differential privacy (DP) [DR14]. DP\
    \ ensures that useful information of a private dataset can be released while simultaneously\
    \ preventing adversaries from identifying individuals' personal data. DP has been\
    \ utilized effectively in a wide variety of settings, by actors including the\
    \ US Census [Abo18] and various large corporations [App17, Fac20, RE19, HBMAL19,\
    \ IBM23].\n\nGenerating private synthetic data is a crucial application of DP.\
    \ It allows data scientists to train their ML models on the synthetic data while\
    \ preserving a certain level of utility when deploying these models on real test\
    \ data. The U.S. National Institute of Standards and Technology (NIST) has emphasized\
    \ its significance by hosting a series of competitions [RTMT21, MMS21]. There\
    \ is also significant work introducing new DP synthetic data generation mechanisms,\
    \ including GAN-based [XLW + 18, BJWW + 19, JYVDS19, TWB + 19], marginal-based\
    \ [ZCP + 17, MSM19, MMS21], and workload-based [VTB + 20, ABK + 21, LVW21, MMSM22,\
    \ VAA + 22] methods. Existing methods for generating private synthetic data are\
    \ task-agnostic-they do not take into account the downstream use cases of the\
    \ synthetic data in the data generation process. However, end users often have\
    \ specific requirements for synthetic datasets to be successfully analyzed by\
    \ their existing data science pipelines, which are often well-established, well-understood,\
    \ heavily vetted, and difficult or expensive to change. Unfortunately, synthetic\
    \ data generated by existing methods may not always meet these requirements, resulting\
    \ in reduced utility for their downstream use cases. This raises a fundamental\
    \ question:\n"
  question: 'How did they demonstrate the success of this method?

    '
task_description: 'extracting content from an email

  '
