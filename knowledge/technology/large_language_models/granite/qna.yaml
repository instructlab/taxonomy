created_by: dxkikuchi
version: 3
domain: IBM Granite Model
document_outline: IBM Granite Knowledge information taken from Wikipedia.
seed_examples:
  - context: >-
      IBM Granite is a series of decoder-only AI foundation models created by
      IBM. It was announced on September 7, 2023, and an initial paper was
      published 4 days later.
    questions_and_answers:
      - question: What is IBM Granite?
        answer: >-
          IBM Granite is a series of decoder-only AI foundation models created
          by IBM.
      - question: When was IBM Granite announced?
        answer: September 7, 2023
      - question: What's a series of decoder-only AI foundation models created by IBM?
        answer: IBM Granite
  - context: >-
      A foundation model is an AI model trained on broad data at scale such that
      it can be adapted to a wide range of downstream tasks.
    questions_and_answers:
      - question: What is a foundation model?
        answer: A foundation model is an AI model trained on broad data at scale.
      - question: What can be adapted to a wide range of downstream tasks?
        answer: >-
          A foundation model is an AI model trained on broad data at scale such
          that it can be adapted to a wide range of downstream tasks.
      - question: What is an AI model trained on broad data at scale?
        answer: >-
          A foundation model is an AI model trained on broad data at scale such
          that it can be adapted to a wide range of downstream tasks.
  - context: >-
      Granite's first foundation models were Granite.13b.instruct and
      Granite.13b.chat. The 13b in their name comes from 13 billion, the amount
      of parameters they have as models, lesser than most of the larger models
      of the time. Later models vary from 3 to 34 billion parameters.
    questions_and_answers:
      - question: What was IBM Granite's first foundation model?
        answer: >-
          Granite's first foundation models were Granite.13b.instruct and
          Granite.13b.chat.
      - question: What does the 13b mean in the IBM Granite model?
        answer: >-
          The 13b in their name comes from 13 billion, the amount of parameters
          they have as models,
      - question: What other amount of parameters are now available?
        answer: Later models vary from 3 to 34 billion parameters.
  - context: >-
      On May 6, 2024, IBM released the source code of four variations of Granite
      Code Models under Apache 2, an open source permissive license that allows
      completely free use, modification and sharing of the software, and put
      them on Hugging Face for public use. According to IBM's own report,
      Granite 8b outperforms Llama 3 on several coding related tasks within
      similar range of parameters.
    questions_and_answers:
      - question: When did IBM release the source code for IBM Granite?
        answer: May 6, 2024
      - question: What license did IBM release the IBM Granite source code?
        answer: Apache 2
      - question: Does IBM Granite 8b outperform Llama 3?
        answer: >-
          According to IBM's own report, Granite 8b outperforms Llama 3 on
          several coding related tasks within similar range of parameters.
  - context: >-
      IBM Granite is a series of decoder-only AI foundation models created by
      IBM. It was announced on September 7, 2023, and an initial paper was
      published 4 days later. Initially intended for use in the IBM's
      cloud-based data and generative AI platform Watsonx along with other
      models, IBM opened the source code of some code models. Granite models are
      trained on datasets curated from Internet, academic publishings, code
      datasets, legal and finance documents.
    questions_and_answers:
      - question: What are IBM Granite model trained on?
        answer: >-
          Granite models are trained on datasets curated from Internet, academic
          publishings, code datasets, legal and finance documents.
      - question: What was IBM Granite initially intended to be used for?
        answer: >-
          Initially intended for use in the IBM's cloud-based data and
          generative AI platform Watsonx
      - question: Did IBM open source Granite?
        answer: 'Yes'
document:
  repo: https://github.com/dxkikuchi/taxonomy-knowledge-docs
  commit: e90cb011ea8fa43d01a8dbfa950ac03b81f24a46
  patterns:
    - IBM-Granite-20241031T160658270.md
